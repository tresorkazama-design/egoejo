# ðŸ” Guide Recherche SÃ©mantique (pgvector) - EGOEJO

**Date** : 2025-01-27  
**Objectif** : PrÃ©parer l'infrastructure pour recherche vectorielle sÃ©mantique

---

## ðŸŽ¯ Objectif

Permettre la recherche sÃ©mantique (concepts, pas mots-clÃ©s) pour relier des contenus conceptuellement proches.

**Exemple** :
- Projet "Permaculture" â†’ Embedding vectoriel
- Contenu "Rudolf Steiner" â†’ Embedding vectoriel
- SimilaritÃ© cosinus â†’ Suggestion automatique

---

## ðŸ“¦ PrÃ©paration (Actuelle)

### 1. Champs Embedding CrÃ©Ã©s

**ModÃ¨les modifiÃ©s** :
- âœ… `EducationalContent.embedding` (JSONField)
- âœ… `Projet.embedding` (JSONField)

**Migration** : `0011_add_embedding_fields.py`

### 2. Structure des Embeddings

Les embeddings seront des vecteurs de dimension 1536 (OpenAI) ou 384 (Sentence Transformers).

**Format JSON** :
```json
{
  "model": "text-embedding-3-small",
  "dimension": 1536,
  "vector": [0.123, -0.456, 0.789, ...]
}
```

---

## ðŸš€ ImplÃ©mentation Future (Phase 2)

### Ã‰tape 1 : Installer pgvector

```bash
# Sur PostgreSQL (Railway ou local)
CREATE EXTENSION IF NOT EXISTS vector;
```

### Ã‰tape 2 : Migration vers VectorField

```python
# Migration future
from pgvector.django import VectorField

class Projet(models.Model):
    # ...
    embedding = VectorField(dimensions=1536, null=True, blank=True)
```

### Ã‰tape 3 : GÃ©nÃ©ration d'Embeddings

**Option A : OpenAI API**
```python
import openai

def generate_embedding(text):
    response = openai.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding
```

**Option B : Sentence Transformers (local)**
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')

def generate_embedding(text):
    return model.encode(text).tolist()
```

### Ã‰tape 4 : Recherche SÃ©mantique

```python
from pgvector.django import L2Distance

def semantic_search(query, limit=10):
    # GÃ©nÃ©rer embedding de la requÃªte
    query_embedding = generate_embedding(query)
    
    # Recherche par similaritÃ© cosinus
    results = Projet.objects.annotate(
        distance=L2Distance('embedding', query_embedding)
    ).order_by('distance')[:limit]
    
    return results
```

---

## ðŸ“‹ Cas d'Usage

### 1. Suggestions de Contenus LiÃ©s

```python
def get_related_contents(projet):
    # Trouver des contenus conceptuellement proches
    related = EducationalContent.objects.annotate(
        similarity=1 - L2Distance('embedding', projet.embedding)
    ).filter(
        similarity__gt=0.7  # Seuil de similaritÃ©
    ).order_by('-similarity')[:5]
    
    return related
```

### 2. Recherche SÃ©mantique AvancÃ©e

```python
def semantic_search_projects(query):
    query_embedding = generate_embedding(query)
    
    # Combiner recherche textuelle (pg_trgm) et sÃ©mantique
    text_results = Projet.objects.search(query)  # pg_trgm
    semantic_results = Projet.objects.annotate(
        similarity=1 - L2Distance('embedding', query_embedding)
    ).filter(similarity__gt=0.6)
    
    # Fusionner les rÃ©sultats
    return (text_results | semantic_results).distinct()
```

### 3. Constellation des Savoirs

Visualiser les liens sÃ©mantiques entre :
- Projets
- Contenus Ã©ducatifs
- Concepts (Steiner, Biodynamie, Permaculture)

---

## ðŸ”§ Configuration Future

### Variables d'Environnement

```env
# Option A : OpenAI
OPENAI_API_KEY=...

# Option B : Sentence Transformers (local)
# Aucune clÃ© nÃ©cessaire
```

### DÃ©pendances Futures

```txt
# requirements.txt (futur)
pgvector>=0.2.0  # Extension PostgreSQL
openai>=1.0.0  # Ou sentence-transformers>=2.2.0
```

---

## ðŸ“Š MÃ©triques de SuccÃ¨s

- **PrÃ©cision suggestions** : > 80%
- **Temps recherche** : < 300ms
- **Couverture sÃ©mantique** : Tous les projets et contenus ont un embedding

---

## ðŸŽ¯ Roadmap

### Phase 1 : PrÃ©paration (Actuelle) âœ…
- [x] Champs embedding crÃ©Ã©s
- [x] Migration prÃ©parÃ©e

### Phase 2 : Infrastructure (Futur)
- [ ] Installer pgvector
- [ ] Migrer vers VectorField
- [ ] Configurer gÃ©nÃ©ration embeddings

### Phase 3 : GÃ©nÃ©ration (Futur)
- [ ] Task Celery pour gÃ©nÃ©rer embeddings
- [ ] GÃ©nÃ©ration automatique Ã  la crÃ©ation
- [ ] Batch processing pour contenus existants

### Phase 4 : Recherche (Futur)
- [ ] Endpoint recherche sÃ©mantique
- [ ] Suggestions automatiques
- [ ] Visualisation constellation

---

**DerniÃ¨re mise Ã  jour** : 2025-01-27  
**Statut** : ðŸ“‹ Infrastructure prÃ©parÃ©e, implÃ©mentation future

