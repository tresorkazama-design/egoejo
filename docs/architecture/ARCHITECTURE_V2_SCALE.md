# üèóÔ∏è Architecture EGOEJO V2 - Scalable & Maintainable

**Date** : 2025-12-16  
**Version** : 2.0.0  
**Statut** : Architecture cible pour la phase "Scale" - Cycles SAKA & Tests de concurrence impl√©ment√©s

---

## 1. Objectif du document

Ce document sert de **boussole technique** pour la phase "Scale" d'EGOEJO. Il d√©crit comment l'architecture passe de "Production Ready" √† "Scalable & Maintainable", en alignant le design technique avec le syst√®me SAKA, les cycles (compost, Silo), la logique 4P (double m√©trique euros / engagement), et les besoins de monitoring et de r√©silience.

**Approche progressive** : Ce document d√©crit l'√©tat cible et les am√©liorations en cours, pas un big bang. On reste sur un **monolithe Django bien structur√©** (pas de microservices pour l'instant), mais avec une organisation du code claire, des services r√©utilisables, et une infrastructure pr√™te √† √©voluer.

---

## 2. Vue d'ensemble de l'architecture

### Vue logique

#### Frontend
- **Stack** : Vite + React 19, PWA (Service Workers), Tailwind CSS, Three.js
- **Tests** : Vitest (unitaires), Playwright (E2E)
- **D√©ploiement** : Vercel (CDN global, edge functions)
- **Build** : Vite production build optimis√© (code splitting, tree shaking)

#### Backend
- **Framework** : Django 5 + Django REST Framework (DRF)
- **T√¢ches asynchrones** : Celery + Redis (broker & backend)
- **WebSockets** : Django Channels + Redis (Channel Layers)
- **D√©ploiement** : Railway (PostgreSQL, Redis, workers Celery)
- **API** : REST + WebSockets pour temps r√©el (chat, polls)

#### Base de donn√©es
- **Principal** : PostgreSQL (production) / SQLite (dev/test)
- **Extensions** : pgvector (recherche s√©mantique), pg_trgm (recherche full-text)
- **Migrations** : Django migrations versionn√©es (0019-0023 pour SAKA)

#### Stockage
- **Statique** : WhiteNoise (compression, cache headers) + CDN Vercel
- **M√©dias** : S3/R2 (production) / FileSystemStorage (dev) - voir section 3

### Flux critiques

#### Authentification
1. **JWT** : Access token (60 min) + Refresh token (7 jours) avec rotation
2. **Session** : Django sessions pour WebSockets (Channels)
3. **Permissions** : DRF permissions + groupes Django (Founders, etc.)

#### SAKA (Protocole d'engagement)
1. **R√©colte** : `harvest_saka()` ‚Üí `SakaTransaction` (EARN) ‚Üí `SakaWallet.balance++`
2. **Plantation** : `spend_saka()` ‚Üí `SakaTransaction` (SPEND) ‚Üí `SakaWallet.balance--`
3. **Boost projet** : Transaction atomique ‚Üí verrouillage wallet + projet ‚Üí `Projet.saka_score++`
4. **Compost** : T√¢che Celery p√©riodique ‚Üí `SakaCompostLog` (li√© √† `SakaCycle`) ‚Üí `SakaSilo.total_balance++`
5. **Cycles** : `SakaCycle` agr√®ge les stats par p√©riode ‚Üí `get_cycle_stats()` calcule r√©colt√©/plant√©/compost√©

#### Cagnottes / Projets
1. **Cr√©ation** : `Projet` ‚Üí `Cagnotte` (optionnel) ‚Üí `Contribution`
2. **Financement** : `WalletTransaction` (PLEDGE_DONATION) ‚Üí `Cagnotte.montant_collecte++`
3. **Boost SAKA** : `POST /api/projets/<pk>/boost/` ‚Üí `Projet.saka_score++`

---

## 3. Stockage & Fichiers (S3 / R2)

### Pourquoi Object Storage en production

Le disque Railway est **√©ph√©m√®re** : lors d'un red√©ploiement ou d'un restart, les fichiers upload√©s sur le syst√®me de fichiers local sont perdus. Les m√©dias (images de projets, avatars, documents) doivent donc √™tre stock√©s dans un **Object Storage** persistant (S3, R2, ou √©quivalent).

### Configuration conditionnelle

Le code utilise `DEFAULT_FILE_STORAGE` conditionn√© par la variable d'environnement `USE_S3_STORAGE` :

```python
# backend/config/settings.py
USE_S3_STORAGE = os.environ.get('USE_S3_STORAGE', 'False').lower() == 'true'

if USE_S3_STORAGE:
    # Configuration S3/R2 (Cloudflare R2 ou AWS S3)
    DEFAULT_FILE_STORAGE = 'storages.backends.s3boto3.S3Boto3Storage'
    # Variables requises : R2_ACCESS_KEY_ID, R2_SECRET_ACCESS_KEY, R2_BUCKET_NAME, R2_ENDPOINT_URL
else:
    # Stockage local (d√©veloppement uniquement)
    MEDIA_URL = '/media/'
    MEDIA_ROOT = BASE_DIR / 'media'
```

### Strat√©gie de d√©ploiement

- **En local/dev** : On reste sur `FileSystemStorage` (simple, rapide pour les tests)
- **En production** : On bascule sur S3-like (R2 Cloudflare recommand√© pour la compatibilit√© S3 + CDN int√©gr√©)

### Variables d'environnement requises (production)

```env
USE_S3_STORAGE=True
R2_ACCESS_KEY_ID=xxx
R2_SECRET_ACCESS_KEY=xxx
R2_BUCKET_NAME=egoejo-media
R2_ENDPOINT_URL=https://xxx.r2.cloudflarestorage.com
R2_CUSTOM_DOMAIN=media.egoejo.org  # Optionnel (CDN)
```

---

## 4. Service Layer & Organisation du code

### Principe de s√©paration des responsabilit√©s

L'architecture suit une s√©paration claire des responsabilit√©s :

- **`models.py`** ‚Üí Uniquement les donn√©es et la logique tr√®s bas niveau (m√©thodes de mod√®le, propri√©t√©s calcul√©es)
- **`api/*.py`** ‚Üí Orchestration HTTP (validation des requ√™tes, formatage des r√©ponses, permissions)
- **`services/*.py`** ‚Üí Logique m√©tier r√©utilisable (SAKA, boosting, calcul 4P, stats)

### Exemples concrets

#### SAKA : Services de transaction

**Fichier** : `backend/core/services/saka.py`

```python
@transaction.atomic
def harvest_saka(user, reason: SakaReason, amount: Optional[int] = None) -> Optional[SakaTransaction]:
    """R√©colter des grains SAKA (Proof of Care)"""
    # Logique : v√©rification limites quotidiennes, cr√©ation transaction, mise √† jour wallet
    ...

@transaction.atomic
def spend_saka(user, amount: int, reason: str, metadata: Optional[dict] = None) -> bool:
    """D√©penser des grains SAKA (vote, boost) - S√âCURIS√â avec select_for_update()"""
    # Logique : v√©rification solde, verrouillage wallet, cr√©ation transaction
    # Protection contre les race conditions via verrous pessimistes
    ...
```

**Utilisation dans les vues** : `backend/core/api/projects.py`

```python
@api_view(['POST'])
def boost_project(request, pk):
    # Validation HTTP
    cost = int(request.data.get("amount", 10))
    
    # Transaction atomique globale avec verrouillage
    with transaction.atomic():
        project = Projet.objects.select_for_update().get(pk=pk)
        
        # Appel service (logique m√©tier avec verrous)
        if not spend_saka(request.user, cost, reason="project_boost"):
            return Response({"detail": "Solde insuffisant"}, status=400)
        
        # Mise √† jour projet (atomique)
        Projet.objects.filter(id=project.id).update(saka_score=F('saka_score') + cost)
```

#### Stats SAKA : Services de calcul

**Fichier** : `backend/core/services/saka_stats.py`

```python
def get_saka_global_stats() -> Dict:
    """Statistiques globales SAKA (utilisateurs, balances, compost)"""
    # Agr√©gations ORM optimis√©es
    ...

def get_saka_daily_stats(days: int = 30) -> List[Dict]:
    """S√©rie temporelle des transactions SAKA par jour"""
    # Groupement par date, agr√©gations
    ...

def get_top_saka_users(limit: int = 10) -> List[Dict]:
    """Top utilisateurs par balance SAKA"""
    # Tri, limite, s√©rialisation
    ...

def get_cycle_stats(cycle: SakaCycle) -> Dict:
    """Statistiques SAKA pour un cycle donn√© (r√©colt√©, plant√©, compost√© par p√©riode)"""
    # Agr√©gation des transactions dans la p√©riode du cycle
    # Somme des compost logs li√©s au cycle
    ...
```

**Utilisation dans les vues** : `backend/core/api/saka_views.py`

```python
@api_view(["GET"])
def saka_stats_view(request):
    # Appel services (logique m√©tier)
    global_stats = get_saka_global_stats()
    daily_stats = get_saka_daily_stats(days=30)
    top_users = get_top_saka_users(limit=10)
    
    # Formatage r√©ponse HTTP
    return Response({"enabled": True, "global": global_stats, ...})

@api_view(["GET"])
def saka_cycles_view(request):
    """Liste des cycles SAKA avec leurs statistiques"""
    cycles = SakaCycle.objects.all().order_by('-start_date')
    
    data = []
    for cycle in cycles:
        stats = get_cycle_stats(cycle)  # Service de calcul
        data.append({
            "id": cycle.id,
            "name": cycle.name,
            "start_date": cycle.start_date.isoformat(),
            "end_date": cycle.end_date.isoformat(),
            "is_active": cycle.is_active,
            "stats": stats,  # R√©colt√©, plant√©, compost√© pour cette p√©riode
        })
    
    return Response(data)
```

### Avantages de cette organisation

1. **Tests unitaires facilit√©s** : Les services sont testables ind√©pendamment des vues HTTP
2. **R√©utilisabilit√©** : Un service peut √™tre appel√© depuis une vue, une t√¢che Celery, ou un management command
3. **Pr√©paration √† l'√©volution** : Si besoin de microservices plus tard, les services sont d√©j√† isol√©s et peuvent √™tre extraits
4. **Maintenabilit√©** : La logique m√©tier est centralis√©e, pas dispers√©e dans les vues

---

## 5. Performance & Cache

### Strat√©gie de cache avec Redis

Redis est utilis√© en priorit√© pour les donn√©es **publiques et agr√©g√©es**, jamais pour les donn√©es **sensibles ou personnelles**.

#### Donn√©es cach√©es (TTL 60-300s)

- **Stats globales SAKA** : `cache.get('saka_global_stats')` ‚Üí TTL 300s
- **Listes de projets publiques** : `cache.get('projets_list')` ‚Üí TTL 60s
- **SakaSilo global** : `cache.get('saka_silo_state')` ‚Üí TTL 180s
- **Top utilisateurs SAKA** : `cache.get('saka_top_users')` ‚Üí TTL 300s

#### Donn√©es jamais cach√©es

- **Solde SAKA utilisateur** : Toujours lu depuis la DB (donn√©es sensibles, changent fr√©quemment)
- **Op√©rations financi√®res** : Wallets, transactions, contributions (donn√©es critiques)
- **Donn√©es d'authentification** : Tokens, sessions (s√©curit√©)

### Invalidation du cache

Le cache est invalid√© lors des **√©critures critiques** :

```python
# Exemple : Boost projet
@api_view(['POST'])
def boost_project(request, pk):
    # ... transaction atomique ...
    
    # Invalidation cache apr√®s √©criture
    cache.delete('projets_list')
    cache.delete('saka_global_stats')
    cache.delete('saka_top_projects')
```

**Apr√®s compost** : Le cache des stats globales SAKA est invalid√© pour refl√©ter le nouveau solde du Silo.

### Configuration Redis

```python
# backend/config/settings.py
REDIS_URL = os.environ.get('REDIS_URL')

if REDIS_URL:
    CACHES = {
        'default': {
            'BACKEND': 'django.core.cache.backends.redis.RedisCache',
            'LOCATION': REDIS_URL.replace('/0', '/1'),  # DB 1 pour cache
            'KEY_PREFIX': 'egoejo',
            'TIMEOUT': 300,  # 5 minutes par d√©faut
        }
    }
else:
    # Fallback : cache en m√©moire (dev uniquement)
    CACHES = {
        'default': {
            'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',
        }
    }
```

**Note** : Redis DB 0 = Channels, DB 1 = Cache, DB 2 = Celery (s√©paration logique).

---

## 6. Monitoring & Observabilit√©

### Sentry : Erreurs & Performance

Sentry est configur√© pour capturer les erreurs backend et tracer les performances des endpoints critiques.

#### Erreurs backend

Toutes les exceptions non g√©r√©es sont envoy√©es √† Sentry avec contexte :
- User ID, IP, User-Agent
- Variables d'environnement (masqu√©es)
- Stack trace compl√®te

#### Performance Monitoring (Sentry Performance)

Les endpoints suivants sont trac√©s pour mesurer les temps de r√©ponse :

- **`/api/saka/*`** : R√©colte, d√©pense, stats
- **`/api/projets/<pk>/boost/`** : Boost projet (transaction atomique critique)
- **`/api/polls/<pk>/vote/`** : Vote quadratique avec SAKA
- **T√¢ches Celery de compost** : `saka_run_compost_cycle` (ex√©cution p√©riodique)

### M√©triques importantes √† surveiller

#### SAKA : Sant√© du syst√®me nerveux

- **Temps moyen d'un boost** : Objectif < 200ms (transaction atomique)
- **Taux d'erreur sur transactions SAKA** : Objectif < 0.1% (erreurs de solde insuffisant exclues)
- **Nombre de composts par cycle** : Suivi via `SakaCompostLog`
- **Taille du SakaSilo** : `SakaSilo.total_balance` (croissance attendue)

#### Infrastructure

- **Temps de r√©ponse API** : P95 < 500ms (hors endpoints lourds)
- **Taux d'erreur global** : < 1%
- **Utilisation Redis** : M√©moire, connexions
- **T√¢ches Celery** : Queue length, temps d'ex√©cution

### Dashboard recommand√©

Un dashboard (Grafana, Sentry Dashboard, ou √©quivalent) devrait afficher :
- Temps de r√©ponse par endpoint SAKA
- Volume de transactions SAKA (r√©colte, d√©pense, compost)
- √âtat du Silo (balance, cycles, derni√®re ex√©cution)
- Erreurs critiques (double d√©pense, solde n√©gatif, etc.)

**Objectif** : Garder un ≈ìil permanent sur la sant√© du "syst√®me nerveux" SAKA.

---

## 7. Concurrence & Int√©grit√© des donn√©es SAKA

### Approche : Verrous pessimistes + Transactions atomiques

Le protocole SAKA garantit l'int√©grit√© des donn√©es m√™me en cas de **concurrence √©lev√©e** (plusieurs utilisateurs boostant le m√™me projet simultan√©ment, votes simultan√©s, etc.).

#### Verrous pessimistes (`select_for_update()`)

Lors des op√©rations critiques, les wallets et projets sont **verrouill√©s** pour √©viter les race conditions :

```python
# Exemple : Boost projet
with transaction.atomic():
    # Verrouiller le projet (bloque les autres requ√™tes jusqu'√† commit)
    project = Projet.objects.select_for_update().get(pk=pk)
    
    # Verrouiller le wallet (dans spend_saka)
    wallet = SakaWallet.objects.select_for_update().get(user=user)
    
    # V√©rifier solde et d√©penser
    if wallet.balance < cost:
        return Response({"detail": "Solde insuffisant"}, status=400)
    
    wallet.balance -= cost
    wallet.save()
    
    # Mettre √† jour projet
    project.saka_score += cost
    project.save()
```

**Effet** : Si deux requ√™tes tentent de booster le m√™me projet simultan√©ment, la seconde attend la fin de la premi√®re (s√©rialisation).

#### Transactions atomiques

Toutes les √©critures SAKA critiques sont dans des **transactions atomiques** :

```python
@transaction.atomic
def spend_saka(user, amount: int, reason: str) -> bool:
    """Soit tout passe, soit rien ne passe"""
    wallet = SakaWallet.objects.select_for_update().get(user=user)
    
    if wallet.balance < amount:
        return False  # Rollback automatique
    
    wallet.balance -= amount
    wallet.save()
    
    SakaTransaction.objects.create(
        user=user,
        direction='SPEND',
        amount=amount,
        reason=reason
    )
    
    return True  # Commit automatique
```

**Effet** : En cas d'erreur, toutes les modifications sont annul√©es (pas de solde partiellement d√©bit√©).

### Tests de concurrence automatis√©s

Les tests utilisent `TransactionTestCase` (au lieu de `TestCase`) pour tester la concurrence r√©elle :

```python
# backend/core/tests_saka.py
class SakaConcurrencyTestCase(TransactionTestCase):
    def test_concurrent_boost_double_spend_prevention(self):
        """Deux boosts simultan√©s ne peuvent pas d√©penser plus que disponible"""
        # Test avec threads r√©els (TransactionTestCase permet la vraie concurrence)
        # Valide que les verrous select_for_update() emp√™chent la double d√©pense
        # V√©rifie que le solde final est coh√©rent (jamais n√©gatif)
        ...
```

**Objectif** : V√©rifier qu'il n'y a pas de double d√©pense, de solde n√©gatif, ou de score incoh√©rent.

### Invariants garantis

Le syst√®me garantit les invariants suivants :

1. **Un solde SAKA ne devient jamais n√©gatif**
   - V√©rification avant chaque d√©pense
   - Verrouillage du wallet pendant la v√©rification + d√©bit

2. **Un boost ne peut pas √™tre appliqu√© si le solde est insuffisant**
   - V√©rification dans `spend_saka()` avant la mise √† jour du projet
   - Transaction atomique : si `spend_saka()` √©choue, le projet n'est pas mis √† jour

3. **Les scores de projet (`saka_score`) sont coh√©rents avec la somme des boosts r√©ussis**
   - Chaque boost r√©ussi incr√©mente `saka_score` de mani√®re atomique
   - Le score peut √™tre recalcul√© depuis `SakaProjectSupport.total_saka_spent` si besoin

4. **Les transactions sont tra√ßables**
   - Chaque op√©ration SAKA cr√©e une `SakaTransaction` avec m√©tadonn√©es
   - Journal complet pour audit et debugging

---

## 8. Alignement avec la philosophie produit

Cette architecture technique permet de supporter les principes fondamentaux d'EGOEJO :

### Temps cyclique (saisons, compost)

Le syst√®me SAKA suit un **cycle naturel** (r√©colte ‚Üí plantation ‚Üí compost) plut√¥t qu'une logique d'accumulation infinie. L'architecture technique le refl√®te :
- **Mod√®le `SakaCycle`** : Repr√©sente les saisons/cycles SAKA (ex: "Saison 2026 - Printemps") avec p√©riode d√©finie (start_date, end_date)
- **T√¢ches Celery p√©riodiques** : Le compost s'ex√©cute automatiquement (tous les lundis √† 3h UTC) et s'associe au cycle actif
- **Mod√®les de cycle** : `SakaCompostLog` enregistre chaque cycle avec ses param√®tres et est li√© √† un `SakaCycle` (optionnel)
- **Stats temporelles** : `get_cycle_stats()` agr√®ge les montants r√©colt√©s, plant√©s et compost√©s par p√©riode, permettant de suivre l'√©volution de l'√©conomie SAKA sur diff√©rentes saisons
- **API des cycles** : `GET /api/saka/cycles/` expose les cycles avec leurs statistiques pour le monitoring et l'affichage frontend

### Double m√©trique (euros / SAKA)

L'architecture s√©pare strictement les **wallets financiers** (`UserWallet`) et les **wallets SAKA** (`SakaWallet`), permettant de mesurer simultan√©ment :
- **P1 (Performance Financi√®re)** : Euros mobilis√©s, investissements
- **P2 (Performance Vivante)** : SAKA r√©colt√©, engag√©, compost√©

L'endpoint `/api/impact/global-assets/` expose les deux m√©triques c√¥te √† c√¥te, offrant une vision compl√®te de la contribution d'un utilisateur.

### Subsidiarit√© (d√©cisions au niveau des communaut√©s)

Les boosts SAKA et votes quadratiques permettent aux utilisateurs d'**influencer directement** les projets qu'ils soutiennent, sans passer par une hi√©rarchie centralis√©e. L'architecture technique le supporte :
- **Endpoints d√©centralis√©s** : `/api/projets/<pk>/boost/` et `/api/polls/<pk>/vote/` sont accessibles √† tous les utilisateurs authentifi√©s
- **Scores agr√©g√©s** : `Projet.saka_score` refl√®te la somme des engagements communautaires
- **Pas de mod√©ration centralis√©e** : Les boosts sont appliqu√©s imm√©diatement (sous r√©serve de solde suffisant)

### Pr√©paration √† l'ouverture de l'API SAKA (futur)

L'organisation en **services r√©utilisables** (`core/services/saka.py`, `saka_stats.py`) pr√©pare l'ouverture future de l'API SAKA √† des partenaires externes :
- Les services peuvent √™tre expos√©s via des endpoints d√©di√©s (`/api/saka/external/`)
- La logique m√©tier est d√©j√† isol√©e et testable
- Les permissions peuvent √™tre √©tendues (tokens API partenaires)

---

## 9. Prochaines √©tapes techniques

### Court terme (1-2 mois)

- ‚úÖ **Finaliser configuration S3 en prod** : Activer `USE_S3_STORAGE=True` sur Railway, configurer R2 Cloudflare
- ‚úÖ **Ajouter plus de tests d'int√©gration SAKA** : Tests boost + compost + cycles dans `tests_saka.py`
- ‚úÖ **Tests de concurrence** : `SakaConcurrencyTestCase` avec threads pour valider la double d√©pense
- ‚úÖ **Mod√®le SakaCycle** : Impl√©ment√© pour agr√©ger les stats par p√©riode
- ‚è≥ **Exposer un endpoint public (read-only) pour les stats globales SAKA/4P** : `/api/public/saka/stats/` (sans authentification, cache 5 min)
- ‚è≥ **Documenter les Feature Flags SAKA** : Ajouter une section dans `PROTOCOLE_SAKA_V2.1.md` expliquant `ENABLE_SAKA`, `SAKA_VOTE_ENABLED`, `SAKA_PROJECT_BOOST_ENABLED`, `SAKA_COMPOST_ENABLED`

### Moyen terme (3-6 mois)

- ‚è≥ **Optimiser les requ√™tes SAKA** : Ajouter des index sur `SakaTransaction` (user, direction, reason, created_at)
- ‚è≥ **Mettre en place un dashboard de monitoring SAKA** : Grafana ou Sentry Dashboard avec m√©triques cl√©s
- ‚è≥ **Am√©liorer la r√©silience Celery** : Retry automatique pour les t√¢ches de compost, alertes sur √©checs
- ‚è≥ **Pr√©parer l'ouverture API SAKA** : Endpoints partenaires, documentation OpenAPI, rate limiting sp√©cifique

### Long terme (6-12 mois)

- ‚è≥ **√âvaluer la n√©cessit√© de microservices** : Si le monolithe devient un goulot d'√©tranglement, extraire les services SAKA dans un service d√©di√©
- ‚è≥ **Mettre en place un syst√®me de redistribution du Silo** : Logique pour redistribuer les grains compost√©s (m√©canisme √† d√©finir)
- ‚è≥ **Int√©grer SAKA dans d'autres domaines** : Chat, contenus √©ducatifs, gouvernance (votes actionnaires V2.0)

---

## üìö Documentation Compl√©mentaire

- **Protocole SAKA** : `PROTOCOLE_SAKA_V2.1.md`
- **Architecture globale** : `ARCHITECTURE_SLEEPING_GIANT_V1.6_V2.0.md`
- **Configuration** : `backend/config/settings.py`
- **Services SAKA** : `backend/core/services/saka.py`, `saka_stats.py`
- **Tests** : `backend/core/tests_saka.py`

---

**Derni√®re mise √† jour** : 2025-12-16  
**Version** : 2.0.0 üèóÔ∏è

