# üî• AUDIT CRITIQUE - Scalabilit√© Backend (100K Utilisateurs)

**Date** : 2025-12-19  
**Auditeur** : Senior Code Auditor (Cynique)  
**Mission** : Crash Test de Scalabilit√© - Identifier les points de rupture √† 100K utilisateurs

---

## üíÄ CRITIQUES MAJEURES

### 1. Compostage : Boucle N+1 avec Saves Individuels = SUICIDE

**Fichier** : `backend/core/services/saka.py:372-409`

**Probl√®me** :
```python
for wallet in qs:  # ‚ùå BOUCLE sur tous les wallets inactifs
    # ...
    wallet.balance -= amount
    wallet.total_composted += amount
    wallet.last_activity_date = timezone.now()
    wallet.save(update_fields=[...])  # ‚ùå SAVE INDIVIDUEL
    
    SakaTransaction.objects.create(  # ‚ùå CREATE INDIVIDUEL
        user=wallet.user,
        # ...
    )
```

**Impact avec 100K utilisateurs** :
- **10% inactifs = 10K wallets**
- **10K `wallet.save()` = 10K requ√™tes UPDATE**
- **10K `SakaTransaction.objects.create()` = 10K requ√™tes INSERT**
- **Total = 20K requ√™tes DB dans une transaction**
- **Temps estim√© : 5-10 minutes** (si DB tient)
- **Verrou DB : Table `SakaWallet` verrouill√©e pendant TOUT le cycle**
- **Timeout garanti**

**Verdict** : **CATASTROPHIQUE**. Code d'amateur qui ne scale pas.

**Fix** :
```python
# Pr√©parer les mises √† jour en batch
wallets_to_update = []
transactions_to_create = []

for wallet in qs:
    # Calculs seulement
    amount = int(floor(wallet.balance * rate))
    if amount < min_amount:
        continue
    
    wallets_to_update.append({
        'id': wallet.id,
        'balance': wallet.balance - amount,
        'total_composted': wallet.total_composted + amount,
        'last_activity_date': timezone.now()
    })
    
    transactions_to_create.append(
        SakaTransaction(
            user_id=wallet.user_id,  # ‚ùå √âVITER wallet.user (N+1)
            direction='SPEND',
            amount=amount,
            reason='compost',
            # ...
        )
    )

# Batch update (1 requ√™te)
SakaWallet.objects.bulk_update(
    [SakaWallet(**w) for w in wallets_to_update],
    ['balance', 'total_composted', 'last_activity_date']
)

# Bulk create (1 requ√™te)
SakaTransaction.objects.bulk_create(transactions_to_create)
```

---

### 2. Redistribution : Chargement de 100K Wallets en M√©moire = OOM

**Fichier** : `backend/core/services/saka.py:584-608`

**Probl√®me** :
```python
eligible_qs = SakaWallet.objects.select_for_update().filter(...)
eligible_wallets = list(eligible_qs)  # ‚ùå CHARGE TOUS EN M√âMOIRE
wallet_ids = [w.id for w in eligible_wallets]

# ...
for wallet in eligible_wallets:  # ‚ùå BOUCLE sur 100K objets
    transactions_to_create.append(
        SakaTransaction(user=wallet.user, ...)  # ‚ùå N+1 si pas select_related
    )
```

**Impact avec 100K utilisateurs** :
- **100K wallets √©ligibles = 100K objets en m√©moire**
- **M√©moire : ~500MB-1GB** (selon taille objets)
- **Out of Memory (OOM) garanti** sur serveur < 4GB RAM
- **M√™me avec RAM suffisante, GC pressure √©norme**

**Verdict** : **MEMORY LEAK MASSIF**. Pas de pagination, pas de chunking.

**Fix** :
```python
# Chunking : Traiter par batches de 1000
BATCH_SIZE = 1000

eligible_ids = list(
    SakaWallet.objects
    .filter(total_harvested__gte=min_activity)
    .values_list('id', flat=True)
)

# Traiter par chunks
for i in range(0, len(eligible_ids), BATCH_SIZE):
    chunk_ids = eligible_ids[i:i + BATCH_SIZE]
    
    # Batch update
    SakaWallet.objects.filter(id__in=chunk_ids).update(
        balance=F('balance') + per_wallet,
        total_harvested=F('total_harvested') + per_wallet,
        last_activity_date=timezone.now()
    )
    
    # Bulk create transactions (avec user_id directement)
    transactions = [
        SakaTransaction(
            user_id=wallet_id,  # ‚ùå BESOIN user_id, pas user
            direction='EARN',
            amount=per_wallet,
            reason='silo_redistribution',
        )
        for wallet_id in chunk_ids
    ]
    SakaTransaction.objects.bulk_create(transactions)
```

**PROBL√àME** : `SakaTransaction` a `user` (ForeignKey), pas `user_id`. **BESOIN DE MIGRATION**.

---

### 3. Redistribution : select_for_update() sur 100K Wallets = DEADLOCK

**Fichier** : `backend/core/services/saka.py:558-562`

**Probl√®me** :
```python
eligible_qs = (
    SakaWallet.objects
    .select_for_update()  # ‚ùå VERROUILLE 100K LIGNES
    .filter(total_harvested__gte=min_activity)
)
```

**Impact avec 100K utilisateurs** :
- **`select_for_update()` verrouille TOUTES les lignes**
- **100K verrous = Deadlock garanti** si autre transaction acc√®de aux wallets
- **Timeout DB : Transaction trop longue**
- **Blocage de TOUTES les op√©rations SAKA** pendant la redistribution

**Verdict** : **DEADLOCK GARANTI**. Verrouillage massif inacceptable.

**Fix** :
```python
# ‚ùå NE PAS utiliser select_for_update() sur toute la table
# Utiliser F() expressions (atomiques) sans verrouillage explicite
# OU verrouiller seulement le Silo (singleton)
```

---

### 4. Compostage : select_for_update() sur QuerySet = VERROU MASSIF

**Fichier** : `backend/core/services/saka.py:353-356`

**Probl√®me** :
```python
qs = SakaWallet.objects.select_for_update().filter(
    last_activity_date__lt=cutoff,
    balance__gte=min_balance,
)
```

**Impact avec 100K utilisateurs** :
- **10K wallets inactifs = 10K verrous**
- **Verrou pendant TOUTE la boucle** (5-10 minutes)
- **Toutes les op√©rations SAKA bloqu√©es**

**Verdict** : **BLOCAGE TOTAL**. Architecture d√©faillante.

**Fix** :
```python
# Ne pas verrouiller les wallets individuellement
# Utiliser F() expressions pour updates atomiques
# Verrouiller seulement le Silo (singleton)
```

---

### 5. harvest_saka : 2 Requ√™tes pour Limite Quotidienne = INEFFICACE

**Fichier** : `backend/core/services/saka.py:135-149`

**Probl√®me** :
```python
today_total = SakaTransaction.objects.filter(...).aggregate(total=Sum('amount'))['total']
# ‚ùå REQU√äTE 1 : SUM

today_count = SakaTransaction.objects.filter(...).count()
# ‚ùå REQU√äTE 2 : COUNT (m√™me filtre)
```

**Impact avec 100K utilisateurs** :
- **2 requ√™tes au lieu d'1** pour chaque `harvest_saka()`
- **Si 1000 r√©coltes/min = 2000 requ√™tes/min inutiles**
- **Charge DB inutile**

**Verdict** : **INEFFICACE**. Requ√™tes dupliqu√©es.

**Fix** :
```python
# Une seule requ√™te avec annotate
from django.db.models import Sum, Count

stats = SakaTransaction.objects.filter(
    user=user,
    direction='EARN',
    reason=reason.value,
    created_at__date=today
).aggregate(
    total=Sum('amount'),
    count=Count('id')
)

today_total = stats['total'] or 0
today_count = stats['count']
```

---

### 6. tasks.py : Boucle avec T√¢ches Celery Individuelles = QUEUE EXPLOSION

**Fichier** : `backend/core/tasks.py:38-51`

**Probl√®me** :
```python
for escrow in escrows:
    if escrow.user and escrow.user.email:
        send_email_task.delay(...)  # ‚ùå T√ÇCHE CELERY PAR EMAIL
```

**Impact avec 100K utilisateurs** :
- **Si 1000 escrows = 1000 t√¢ches Celery cr√©√©es**
- **Queue Celery satur√©e**
- **Latence √©norme**
- **Memory leak si queue non vid√©e**

**Verdict** : **QUEUE EXPLOSION**. Pas de batching.

**Fix** :
```python
# Grouper les emails par batch
emails_batch = [
    (escrow.user.email, subject, html_content)
    for escrow in escrows
    if escrow.user and escrow.user.email
]

# Une seule t√¢che pour envoyer tous les emails
send_bulk_email_task.delay(emails_batch)
```

---

### 7. Compostage : Pas de Pagination/Chunking = TIMEOUT

**Fichier** : `backend/core/services/saka.py:372`

**Probl√®me** :
```python
for wallet in qs:  # ‚ùå TOUS les wallets en une fois
```

**Impact avec 100K utilisateurs** :
- **10K wallets trait√©s en une transaction**
- **Transaction trop longue = Timeout**
- **Rollback complet si erreur**

**Verdict** : **TIMEOUT GARANTI**. Pas de chunking.

**Fix** :
```python
# Traiter par chunks de 500
BATCH_SIZE = 500
offset = 0

while True:
    chunk = qs[offset:offset + BATCH_SIZE]
    if not chunk.exists():
        break
    
    # Traiter le chunk
    # ...
    
    offset += BATCH_SIZE
```

---

### 8. Redistribution : Pas de select_related() = N+1 Queries

**Fichier** : `backend/core/services/saka.py:584-605`

**Probl√®me** :
```python
eligible_wallets = list(eligible_qs)  # ‚ùå Pas de select_related('user')

for wallet in eligible_wallets:
    transactions_to_create.append(
        SakaTransaction(user=wallet.user, ...)  # ‚ùå N+1 si pas select_related
    )
```

**Impact avec 100K utilisateurs** :
- **100K wallets = 100K requ√™tes `SELECT user FROM User WHERE id=...`**
- **Total = 100K requ√™tes inutiles**
- **DB satur√©e**

**Verdict** : **N+1 QUERIES MASSIF**. Amateur.

**Fix** :
```python
# Utiliser user_id directement (si migration faite)
# OU select_related('user')
eligible_qs = SakaWallet.objects.select_related('user').filter(...)
```

---

## üî• POINTS DE RUPTURE PAR CAT√âGORIE

### Performance Critique
1. ‚ùå Compostage : 20K requ√™tes DB (saves individuels)
2. ‚ùå Redistribution : 100K objets en m√©moire (OOM)
3. ‚ùå Compostage : Pas de chunking (timeout)
4. ‚ùå Redistribution : Pas de chunking (timeout)

### Verrous DB
5. ‚ùå `select_for_update()` sur 100K wallets (deadlock)
6. ‚ùå Transaction trop longue (timeout)
7. ‚ùå Verrouillage de toute la table `SakaWallet`

### Memory Leaks
8. ‚ùå Chargement de 100K wallets en m√©moire
9. ‚ùå Pas de pagination/chunking
10. ‚ùå GC pressure √©norme

### N+1 Queries
11. ‚ùå 2 requ√™tes pour limite quotidienne (harvest_saka)
12. ‚ùå Pas de select_related('user') (redistribution)
13. ‚ùå Boucle avec wallet.user (N+1)

### Architecture
14. ‚ùå Pas de batching pour emails (tasks.py)
15. ‚ùå Pas de migration pour user_id (SakaTransaction)

---

## üí£ SCORE DE RUPTURE

| Service | Score Rupture | Verdict |
|---------|---------------|---------|
| `run_saka_compost_cycle` | **10/10** | üíÄ Critique - Ne scale pas |
| `redistribute_saka_silo` | **9/10** | üíÄ Critique - OOM + Deadlock |
| `harvest_saka` | **5/10** | ‚ö†Ô∏è Inefficace |
| `tasks.py` | **6/10** | ‚ö†Ô∏è Queue explosion |

**Score Global** : **8/10 - PROJET NE SCALE PAS**

---

## üéØ REFACTORISATION MASSIVE (Par Priorit√©)

### üî¥ PRIORIT√â 1 : Fix Compostage (4h)
1. **Batch Update** : Remplacer `wallet.save()` par `bulk_update()`
2. **Bulk Create** : Remplacer `create()` par `bulk_create()`
3. **Chunking** : Traiter par batches de 500
4. **Retirer select_for_update()** : Utiliser F() expressions

**Code Refactoris√©** :
```python
def run_saka_compost_cycle(dry_run: bool = False, source: str = "celery") -> Dict:
    # ... config ...
    
    BATCH_SIZE = 500
    offset = 0
    total_composted = 0
    affected = 0
    
    while True:
        # Chunk de wallets
        chunk = SakaWallet.objects.filter(
            last_activity_date__lt=cutoff,
            balance__gte=min_balance,
        )[offset:offset + BATCH_SIZE]
        
        if not chunk.exists():
            break
        
        wallets_to_update = []
        transactions_to_create = []
        
        for wallet in chunk:
            amount = int(floor(wallet.balance * rate))
            if amount < min_amount:
                continue
            
            wallets_to_update.append(SakaWallet(
                id=wallet.id,
                balance=wallet.balance - amount,
                total_composted=wallet.total_composted + amount,
                last_activity_date=timezone.now()
            ))
            
            transactions_to_create.append(SakaTransaction(
                user_id=wallet.user_id,  # ‚ùå BESOIN user_id
                direction='SPEND',
                amount=amount,
                reason='compost',
                metadata={...}
            ))
        
        if not dry_run and wallets_to_update:
            # Batch update
            SakaWallet.objects.bulk_update(
                wallets_to_update,
                ['balance', 'total_composted', 'last_activity_date']
            )
            
            # Bulk create
            SakaTransaction.objects.bulk_create(transactions_to_create)
            
            # Mise √† jour Silo (une seule fois par chunk)
            SakaSilo.objects.filter(id=1).update(
                total_balance=F('total_balance') + sum(t.amount for t in transactions_to_create),
                total_composted=F('total_composted') + sum(t.amount for t in transactions_to_create),
            )
        
        total_composted += sum(t.amount for t in transactions_to_create)
        affected += len(wallets_to_update)
        offset += BATCH_SIZE
    
    # ...
```

---

### üü° PRIORIT√â 2 : Fix Redistribution (3h)
1. **Chunking** : Traiter par batches de 1000
2. **Retirer select_for_update()** : Utiliser F() expressions
3. **Migration user_id** : Ajouter `user_id` √† `SakaTransaction`
4. **√âviter list()** : Utiliser `values_list('id', flat=True)`

**Code Refactoris√©** :
```python
def redistribute_saka_silo(rate: float | None = None) -> Dict:
    # ... config ...
    
    BATCH_SIZE = 1000
    
    # R√©cup√©rer seulement les IDs (pas les objets)
    eligible_ids = list(
        SakaWallet.objects
        .filter(total_harvested__gte=min_activity)
        .values_list('id', flat=True)
    )
    
    if not eligible_ids:
        return {"ok": False, "reason": "no_eligible_wallets"}
    
    per_wallet = total_to_redistribute // len(eligible_ids)
    
    # Traiter par chunks
    for i in range(0, len(eligible_ids), BATCH_SIZE):
        chunk_ids = eligible_ids[i:i + BATCH_SIZE]
        
        # Batch update (atomique avec F())
        SakaWallet.objects.filter(id__in=chunk_ids).update(
            balance=F('balance') + per_wallet,
            total_harvested=F('total_harvested') + per_wallet,
            last_activity_date=timezone.now()
        )
        
        # Bulk create transactions
        transactions = [
            SakaTransaction(
                user_id=wallet_id,  # ‚ùå BESOIN user_id
                direction='EARN',
                amount=per_wallet,
                reason='silo_redistribution',
            )
            for wallet_id in chunk_ids
        ]
        SakaTransaction.objects.bulk_create(transactions)
    
    # Mise √† jour Silo (une seule fois)
    actual_redistributed = per_wallet * len(eligible_ids)
    SakaSilo.objects.filter(id=1).update(
        total_balance=F('total_balance') - actual_redistributed
    )
    
    # ...
```

---

### üü¢ PRIORIT√â 3 : Fix harvest_saka (1h)
1. **Une seule requ√™te** : Utiliser `aggregate()` avec `Sum` et `Count`
2. **Optimiser** : R√©duire de 2 requ√™tes √† 1

---

### üîµ PRIORIT√â 4 : Fix tasks.py (1h)
1. **Batching emails** : Grouper les emails en une seule t√¢che
2. **√âviter queue explosion** : Limiter le nombre de t√¢ches

---

## üìã MIGRATIONS REQUISES

### Migration 1 : Ajouter user_id √† SakaTransaction
```python
# migrations/XXXX_add_user_id_to_saka_transaction.py
from django.db import migrations, models

class Migration(migrations.Migration):
    dependencies = [
        ('core', 'XXXX_previous'),
    ]

    operations = [
        migrations.AddField(
            model_name='sakatransaction',
            name='user_id',
            field=models.IntegerField(null=True),
        ),
        # Populate user_id from user
        migrations.RunPython(populate_user_id),
        # Make user_id not null
        migrations.AlterField(
            model_name='sakatransaction',
            name='user_id',
            field=models.IntegerField(),
        ),
    ]
```

---

## üéØ ESTIMATION TEMPS

| T√¢che | Temps | Priorit√© |
|-------|-------|----------|
| Fix Compostage | 4h | üî¥ Critique |
| Fix Redistribution | 3h | üî¥ Critique |
| Fix harvest_saka | 1h | üü° Important |
| Fix tasks.py | 1h | üü° Important |
| Migration user_id | 2h | üî¥ Critique |
| **TOTAL** | **11h** | |

---

## üí£ VERDICT FINAL

**Le code actuel NE SCALE PAS √† 100K utilisateurs.**

**Points de rupture critiques** :
1. **Compostage** : 20K requ√™tes DB = Timeout garanti
2. **Redistribution** : 100K objets en m√©moire = OOM garanti
3. **Verrous DB** : Deadlock garanti
4. **Pas de chunking** : Transactions trop longues

**Refactorisation massive requise avant production √† grande √©chelle.**

---

**Document g√©n√©r√© le : 2025-12-19**  
**Auditeur : Senior Code Auditor (Cynique)**  
**Statut : üî• POINTS DE RUPTURE IDENTIFI√âS - REFACTORISATION URGENTE**

